const fetch = require('node-fetch');
const { spawn } = require("child_process");
const { models } = require('./models'); 

const API_URL = "https://openrouter.ai/api/v1/chat/completions";

/**
 * ğŸ”¹ Gá»i API AI Ä‘á»ƒ trÃ² chuyá»‡n
 * @param {Array} history - Lá»‹ch sá»­ tin nháº¯n (máº£ng tin nháº¯n trÆ°á»›c Ä‘Ã³)
 * @param {string} content - Ná»™i dung tin nháº¯n má»›i
 * @param {string} modelKey - Model AI cáº§n sá»­ dá»¥ng (máº·c Ä‘á»‹nh lÃ  "3")
 * @param {Array} images - Danh sÃ¡ch URL áº£nh gá»­i kÃ¨m
 * @returns {Promise<string>} - Pháº£n há»“i tá»« AI
 */
async function chatWithAI(history, content, modelKey = "3", images = []) {
    const MAX_RETRIES = 3;
    let retryCount = 0;

    const selectedModel = models[modelKey]?.modelId || models["2"].modelId;
    let formattedMessages = history;

    // ğŸ”¹ Náº¿u sá»­ dá»¥ng Google Gemini Pro (Model 3) vÃ  cÃ³ áº£nh
    if (modelKey === "3" && images.length > 0) {
        formattedMessages = [
            {
                role: "user",
                content: [
                    { type: "text", text: content },
                    ...images.map(url => ({ type: "image_url", image_url: { url } }))
                ]
            }
        ];
    } else {
        formattedMessages.push({ role: "user", content: content });
    }

    while (retryCount < MAX_RETRIES) {
        try {
            const response = await fetch(API_URL, {
                method: "POST",
                headers: {
                    "Authorization": `Bearer ${process.env.OPENROUTER_API_KEY}`,
                    "Content-Type": "application/json"
                },
                body: JSON.stringify({
                    model: selectedModel,
                    messages: formattedMessages,
                    temperature: 0.5,
                    max_tokens: 4096
                }),
                timeout: 20000
            });

            const data = await response.json();
            console.log('ğŸ“Œ API Response:', JSON.stringify(data, null, 2));
            
            if (!data?.choices?.[0]?.message?.content) {
                throw new Error(`âŒ Lá»—i response tá»« AI: ${JSON.stringify(data)}`);
            }

            return data.choices[0].message.content;

        } catch (error) {
            retryCount++;
            
            if (error.response?.status === 429) {
                const waitTime = Math.pow(2, retryCount) * 10000;
                console.log(`â³ Rate limited. Retry ${retryCount} in ${waitTime}ms`);
                await new Promise(resolve => setTimeout(resolve, waitTime));
                continue;
            }

            console.error('âŒ Lá»—i API AI:', error);
            if (retryCount === MAX_RETRIES) {
                return "ğŸ”§ Há»‡ thá»‘ng Ä‘ang báº£o trÃ¬, vui lÃ²ng thá»­ láº¡i sau!";
            }
        }
    }
    return "â³ Server Ä‘ang quÃ¡ táº£i, thá»­ láº¡i sau...";
}



/**
 * ğŸ”¹ Gá»i `embedder.py` Ä‘á»ƒ táº¡o vector embeddings
 * @param {Array|string} texts - VÄƒn báº£n cáº§n táº¡o embeddings (1 chuá»—i hoáº·c danh sÃ¡ch chuá»—i)
 * @returns {Promise<Array>} - Embeddings tráº£ vá» tá»« Python
 */
function getEmbedding(texts) {
    return new Promise((resolve, reject) => {
        const py = spawn("python3", ["embedder.py"]);

        let data = "";
        let errorData = "";

        console.log("ğŸ“Œ [DEBUG] Báº¯t Ä‘áº§u gá»i Python embedding...");

        py.stdout.on("data", (chunk) => {
            data += chunk;
            //console.log("ğŸ“¥ [DEBUG] Python stdout:", chunk.toString());
        });

        py.stderr.on("data", (chunk) => {
            errorData += chunk;
            //console.error("âŒ [DEBUG] Python stderr:", chunk.toString());
        });

        py.on("close", (code) => {
            console.log(`ğŸ“Œ [DEBUG] Python process exited with code ${code}`);

            if (code !== 0 || errorData) {
                console.error("âŒ Python Error:", errorData);
                reject(new Error(`Python process exited with error: ${errorData}`));
                return;
            }

            try {
                const result = JSON.parse(data.trim());
                if (result.error) {
                    reject(new Error(`Python Error: ${result.error}`));
                } else {
                    //console.log("âœ… [DEBUG] Embedding nháº­n Ä‘Æ°á»£c:", result);
                    resolve(result);
                }
            } catch (err) {
                console.error("âŒ [DEBUG] JSON parse error:", err);
                reject(new Error("Invalid JSON response from Python."));
            }
        });

        // ğŸ”¹ Kiá»ƒm tra dá»¯ liá»‡u Ä‘áº§u vÃ o trÆ°á»›c khi gá»­i
        if (!texts || (Array.isArray(texts) && texts.length === 0)) {
            console.error("âš ï¸ Dá»¯ liá»‡u Ä‘áº§u vÃ o rá»—ng!");
            reject(new Error("No input data provided."));
            return;
        }

        const inputData = JSON.stringify(Array.isArray(texts) ? texts : [texts]);
        console.log("ğŸ“¤ [DEBUG] Gá»­i dá»¯ liá»‡u vÃ o Python:", inputData);
        py.stdin.write(inputData); // ğŸ”¹ Gá»­i JSON vÃ o stdin cá»§a Python
        py.stdin.end();
    });
}

// ğŸ”¹ Xuáº¥t module
module.exports = { chatWithAI, getEmbedding };
